"""Router for model upload and management."""

from typing import Annotated
from uuid import UUID

from fastapi import (
    APIRouter,
    Depends,
    File,
    Query,
    Request,
    Response,
    UploadFile,
    status,
)
from huggingface_hub import model_info
from huggingface_hub.errors import EntryNotFoundError, HfHubHTTPError
from loguru import logger
from sqlmodel.ext.asyncio.session import AsyncSession

from vectorize.ai_model.exceptions import ModelNotFoundError
from vectorize.ai_model.model_source import RemoteModelSource
from vectorize.ai_model.service import get_ai_model_svc
from vectorize.common.exceptions import InternalServerError, InvalidFileError
from vectorize.config.db import get_session
from vectorize.task.task_status import TaskStatus

from .exceptions import InvalidUrlError, ModelAlreadyExistsError
from .exceptions import ModelNotFoundError as RepoModelNotFound
from .github_service import repo_info
from .local_service import upload_zip_model
from .models import UploadTask
from .repository import get_upload_task_by_id_db, save_upload_task_db
from .schemas import GitHubModelRequest, HuggingFaceModelRequest
from .tasks import process_github_model_bg, process_huggingface_model_bg

router = APIRouter(tags=["AIModel Upload"])


@router.post("/huggingface")
async def load_model_huggingface(
    data: HuggingFaceModelRequest,
    request: Request,
    db: Annotated[AsyncSession, Depends(get_session)],
) -> Response:
    """Upload a Hugging Face model by model_tag and revision.

    Checks if the model already exists, verifies its presence on
    Hugging Face, creates an upload task, and starts background
    processing. Returns a 201 response with a Location header.

    Args:
        data: Model tag and revision for Hugging Face.
        request: FastAPI request object.
        db: Async database session.

    Returns:
        Response with 201 status and Location header.

    Raises:
        ModelAlreadyExistsError: If the model already exists in the database.
        ModelNotFoundError: If the model is not found on Hugging Face.
        InternalServerError: If an internal error occurs while checking the model.
    """
    key = f"{data.model_tag}@{data.revision}"
    # Convert model_tag to the same format as stored in the database
    db_model_tag = data.model_tag.replace("/", "_")

    try:
        await get_ai_model_svc(db, db_model_tag)
        raise ModelAlreadyExistsError(db_model_tag)
    except ModelNotFoundError:
        pass

    try:
        model_info(repo_id=data.model_tag, revision=data.revision)
    except (EntryNotFoundError, HfHubHTTPError) as e:
        raise ModelNotFoundError(data.model_tag, data.revision) from e
    except Exception as e:
        raise InternalServerError(
            "Internal server error while checking model on Hugging Face.",
        ) from e

    upload_task = UploadTask(
        tag=key,
        task_status=TaskStatus.RUNNING,
        source=RemoteModelSource.HUGGINGFACE,
        model_tag=key,
    )
    await save_upload_task_db(db, upload_task)
    process_huggingface_model_bg.send(
        data.model_tag, data.revision, str(upload_task.id)
    )

    return Response(
        status_code=status.HTTP_201_CREATED,
        headers={"Location": f"{request.base_url}upload/tasks/{upload_task.id}"},
    )


@router.post("/github")
async def load_model_github(
    data: GitHubModelRequest,
    request: Request,
    db: Annotated[AsyncSession, Depends(get_session)],
) -> Response:
    """Upload a Github model by url.

    Checks if the model already exists, verifies its presence in the
    Github Repository, creates an upload task, and starts background
    processing. Returns a 201 response with a Location header.

    Args:
        data: The GitHub Model request Url object
        request: FastAPI request object.
        background_tasks: FastAPI background task manager.
        db: Async database session.

    Returns:
        Response with 201 status and Location header.
    """
    branch = data.revision or "main"
    key = f"{data.owner}/{data.repo_name}@{branch}"
    base_url = f"https://github.com/{data.owner}/{data.repo_name}"

    logger.info("Importing GitHub model {} @ {}", data.repo_name, branch)

    try:
        await get_ai_model_svc(db, key)
        raise ModelAlreadyExistsError(key)
    except ModelNotFoundError:
        pass

    try:
        await repo_info(repo_url=base_url, revision=branch)
    except (RepoModelNotFound, InvalidUrlError):
        raise
    except Exception as e:
        raise InternalServerError("Error checking GitHub repository") from e

    upload_task = UploadTask(
        tag=key, task_status=TaskStatus.RUNNING, source=RemoteModelSource.GITHUB
    )

    await save_upload_task_db(db, upload_task)
    process_github_model_bg.send(
        data.owner, data.repo_name, branch, str(upload_task.id)
    )
    return Response(
        status_code=status.HTTP_201_CREATED,
        headers={"Location": f"{request.base_url}upload/tasks/{upload_task.id}"},
    )


@router.post("/local", summary="Upload multiple models from a ZIP archive")
async def load_model_local(
    file: Annotated[UploadFile, File()],
    request: Request,
    db: Annotated[AsyncSession, Depends(get_session)],
    model_name: Annotated[
        str | None, Query(description="Base name for models (optional)")
    ] = None,
) -> Response:
    """Upload a ZIP archive containing multiple model directories.

    Each top-level directory in the ZIP will be treated as a separate model.
    All extracted models will be registered in the database.

    Args:
        file: ZIP archive containing model directories
        request: HTTP request object
        model_name: Optional base name for models (used as fallback)
        db: Database session

    Returns:
        Response with 201 status and Location header

    Raises:
        InvalidFileError: If no file is provided or format is invalid
        HTTPException: If an error occurs during processing
    """
    if not file.filename or not file.filename.lower().endswith(".zip"):
        raise InvalidFileError("Only ZIP archives are supported")

    logger.debug(
        "Multi-model ZIP upload: '{}' with {} bytes",
        file.filename,
        file.size if hasattr(file, "size") else "unknown size",
    )

    result = await upload_zip_model(file, model_name, db, multi_model=True)

    model_count = result["total_models"]
    logger.info(f"Successfully uploaded {model_count} models from ZIP archive")

    headers = {}
    if result["models"]:
        first_model = result["models"][0]
        model_id = (
            first_model.get("id")
            or first_model.get("model_id")
            or first_model.get("model_tag")
        )
        if model_id:
            headers["Location"] = f"{request.url}/{model_id}"

    return Response(
        status_code=status.HTTP_201_CREATED,
        headers=headers,
    )


@router.get("/{task_id}", summary="Get status of a model upload task")
async def get_upload_status(
    task_id: UUID,
    db: Annotated[AsyncSession, Depends(get_session)],
) -> UploadTask:
    """Endpoint to retrieve the status of an upload task by its ID."""
    task = await get_upload_task_by_id_db(db, task_id)
    if not task:
        raise ModelNotFoundError(f"Upload task with ID {task_id} not found")

    return task
